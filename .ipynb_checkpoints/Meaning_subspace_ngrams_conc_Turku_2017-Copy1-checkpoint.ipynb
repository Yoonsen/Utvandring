{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for meaning and variation\n",
    "\n",
    "Turku/Åbo 2017\n",
    "\n",
    "This notebook is for investigating texts from the collection of digitized text at the Norwegian National Library: http://www.nb.no. Access is via an API which resides at http://api.nb.no/ngram, which the code provides an interface to. Some of texts (books) can be freely downloaded from https://www.nb.no/sprakbanken/show?serial=oai%3Anb.no%3Asbr-34&lang=en. \n",
    "\n",
    "There is code for fetching references to books via URNs, plotting trendlines for words, and getting concordances.\n",
    "\n",
    "One way of comparing texts is to look at frequencies of a selected number of words. For this purpose heatmaps are used, which performs a kind of visual relativization of data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import json\n",
    "import requests\n",
    "from IPython.display import HTML\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "sns.set_style('white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Program code (activate and scroll past it ...)\n",
    " \n",
    " The functions defined below provide an interface, and serve as an example of how to use the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ngrams(words, params={}, delta='og'):\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    result = dict()\n",
    "    found_word = False\n",
    "    for word in words + [delta]:\n",
    "        params['word'] = word\n",
    "        r = requests.get(\"https://api.nb.no/ngram/ngram\", params)   \n",
    "        if r.status_code==200:\n",
    "            result[word] = r.json()\n",
    "            found_word=True\n",
    "\n",
    "    if found_word==True:\n",
    "        temp = pd.DataFrame(result)\n",
    "        if delta != \"\":\n",
    "            res = temp[words].divide(temp[delta], axis=0)\n",
    "        else:\n",
    "            res = temp\n",
    "    else:\n",
    "        res = r\n",
    "    return res\n",
    "\n",
    "def get_ngram(word, params=dict()):\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    para = params\n",
    "    para['word']= word\n",
    "    r = requests.get('https://api.nb.no/ngram/ngram', params=para)\n",
    "    r = pd.DataFrame.from_dict(r.json(), orient='index').sort_index()\n",
    "    #r.columns = [word]\n",
    "    return r\n",
    "\n",
    "\n",
    "def heatmap(df, color='red'):\n",
    "    return df.fillna(0).style.background_gradient(cmap=sns.light_palette(color, as_cmap=True))\n",
    "\n",
    "def get_freq(words, params=dict()):\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    para = params\n",
    "    para['words']= words\n",
    "    r = requests.post('https://api.nb.no/ngram/freq', json = para)\n",
    "    #r.columns = [word]\n",
    "    return r.json()\n",
    "\n",
    "def get_urns(params=dict()):\n",
    "    import requests\n",
    "    \n",
    "    para = params\n",
    "    r = requests.get('https://api.nb.no/ngram/urn', json = para)\n",
    "    #r.columns = [word]\n",
    "    return r.json()\n",
    "\n",
    "def get_urnfreq(urn, top=10, cutoff=10):\n",
    "    params = dict()\n",
    "    params['urn'] = urn\n",
    "    params['top'] = top\n",
    "    params['cutoff'] = cutoff\n",
    "    r = requests.get('https://api.nb.no/ngram/urnfreq', json = params)\n",
    "    return r.json()\n",
    "    \n",
    "\n",
    "def get_konk(word, url='konk',  params=dict(), html=True):\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    para = params\n",
    "    para['word']= word\n",
    "    r = requests.get('https://api.nb.no/ngram/{url}'.format(url=url), params=para)\n",
    "    if html:\n",
    "        rows = \"\"\n",
    "        for x in r.json():\n",
    "            rows += \"\"\"<tr>\n",
    "            <td>\n",
    "                <a href='{urn}' target='_'>{urnredux}</a>\n",
    "                <td>{b}</td>\n",
    "                <td>{w}</td>\n",
    "                <td style='text-align:left'>{a}</td>\n",
    "                </tr>\\n\"\"\".format(urn=x['urn'], \n",
    "                                  urnredux=','.join([x['author'], x['title'], str(x['year'])]),\n",
    "                                  b=x['before'],\n",
    "                                  w=x['word'],\n",
    "                                  a=x['after']\n",
    "                                 )\n",
    "        res = \"<table>{rows}</table>\".format(rows=rows)   \n",
    "    else:\n",
    "        try:\n",
    "            res = pd.DataFrame(r.json())\n",
    "            res = res[['urn','author','title','year','before','word','after']]\n",
    "        except:\n",
    "            res= pd.DataFrame()\n",
    "        #r = r.style.set_properties(subset=['after'],**{'text-align':'left'})\n",
    "    return res    \n",
    "    \n",
    "def plotrelative(ng1, ng2, period=(1850, 2005), window=2, figsize=(15,8), legend=False, title='Relative trend', ymin = 0):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    (ng1/ng2).loc[str(period[0]):str(period[1])].rolling(window, win_type='triang').mean().plot(legend=legend, title=title, figsize=figsize);\n",
    "    fymin, fymax = plt.ylim()\n",
    "    plt.ylim(ymin, fymax)\n",
    "    return\n",
    "\n",
    "\n",
    "def get_urnkonk(word, params=dict(), html=True):\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    para = params\n",
    "    para['word']= word\n",
    "    r = requests.post('https://api.nb.no/ngram/urnkonk', json = para)\n",
    "    if html:\n",
    "        rows = \"\"\n",
    "        for x in r.json():\n",
    "            rows += \"\"\"<tr>\n",
    "                <td>\n",
    "                    <a href='{urn}' target='_blank' style='text-decoration:none'>{urnredux}</a>\n",
    "                </td>\n",
    "                <td>{b}</td>\n",
    "                <td>{w}</td>\n",
    "                <td style='text-align:left'>{a}</td>\n",
    "            </tr>\\n\"\"\".format(urn=x['urn'],\n",
    "                              urnredux=\"{t}, {f}, {y}\".format(t=x['title'], f=x['author'], y=x['year']),\n",
    "                              b=x['before'],\n",
    "                              w=x['word'],\n",
    "                              a=x['after']\n",
    "                             )\n",
    "        res = \"\"\"<table>{rows}</table>\"\"\".format(rows=rows)    \n",
    "    else:\n",
    "        res = pd.DataFrame(r.json())\n",
    "        res = res[['urn','before','word','after']]\n",
    "        #r = r.style.set_properties(subset=['after'],**{'text-align':'left'})\n",
    "    return res\n",
    "\n",
    "def trend_plot(df,yf='1880',yt='2000', window=3, legend=False, title='Trend'):\n",
    "    df.loc[yf:yt].rolling(window=window).mean().plot(figsize=(15,8),legend=legend, title=title)\n",
    "    return\n",
    "    \n",
    "def periods(p_start, p_end, step):\n",
    "    årstall = list(range(p_start, p_end, step))\n",
    "    ypairs = []\n",
    "    for i in range(len(årstall) - 1):\n",
    "        ypairs.append((årstall[i], årstall[i+1]))\n",
    "    return ypairs\n",
    "    \n",
    "def barplot(df):\n",
    "    df.fillna(0).plot(kind='bar',figsize=(15,8), color= sns.hls_palette(len(df), l=.4, s=.9));\n",
    "    return \n",
    "\n",
    "def dewey_dist(word):\n",
    "    res = dict()\n",
    "    for i in range(10):\n",
    "        dta = get_ngram(word, params={'corpus':'bok','ddk':i}).sum()\n",
    "        res[str(i*100)] = dta\n",
    "    return res\n",
    "\n",
    "def js_delta(js1, js2):\n",
    "    # Arguments as json, output a dataframe\n",
    "    return pd.DataFrame.from_dict(js1, orient='index')/pd.DataFrame.from_dict(js2, orient='index')\n",
    "\n",
    "def get_words_from_urnset(words, urnset):\n",
    "    urns = dict()\n",
    "    for urn in urnset:\n",
    "        urns[urn] = dict(get_freq(words, {'urn':urn}))\n",
    "    return urns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordances\n",
    "\n",
    "Investigate a word with the function *get_konk*. It returns a concordance of the key word along with a link to metadata and the full text. If you live outside Norway, go to https://www.nb.no/samlingen/bokhylla-utlandet and apply for a permission to read texts published up to the year 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2012081309027' target='_'>Nilsson, Lars Petter,XRF feltmålinger (TiO₂ og Fetot.) og magnetiske susceptibilitetsmålinger på mineraliseringer av jern-titan oksyder i den sydlige delen av Bjerkreim-Sokndal intrusjonen, Sokndal kommune, Rogaland,1996</a>\n",
       "                <td>. Ved intens bruk gikk imidlertid batteriet tomt etter ca. 7 timers</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>, noe som hendte oss et par ganger .</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2014052008079' target='_'>Lingjærde, Christine,Introduksjon til fransk politikk og samfunnsliv,1994</a>\n",
       "                <td>var det fire millioner av dem , hvorav 1,75 millioner var i</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>, omtrent én av 12 av den totale arbeidsstyrken.</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2014052008079' target='_'>Lingjærde, Christine,Introduksjon til fransk politikk og samfunnsliv,1994</a>\n",
       "                <td>travail indépendant ( m ) : selvstendig</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>None</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2014052008079' target='_'>Lingjærde, Christine,Introduksjon til fransk politikk og samfunnsliv,1994</a>\n",
       "                <td>emploi de proximité ( m ) :</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>hos bekjente</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2014052008079' target='_'>Lingjærde, Christine,Introduksjon til fransk politikk og samfunnsliv,1994</a>\n",
       "                <td>réinsertion ( f ) : tilbakeføring i</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>None</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2013041805118' target='_'>Bjørkum, Åshild,Taeko og den gode nyheten,1977</a>\n",
       "                <td>mor og far holder på å stå opp . Far skal på</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>i banken og må tidlig av garde for å nå det .</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2013041805118' target='_'>Bjørkum, Åshild,Taeko og den gode nyheten,1977</a>\n",
       "                <td>Når far kommer fra</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>, kjenner Taeko og Masao at de er sultne . De henger</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2013041805118' target='_'>Bjørkum, Åshild,Taeko og den gode nyheten,1977</a>\n",
       "                <td>sant , det er jo søndag , og far skal ikke på</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>. Da husker hun plutselig at hun skal på søndagsskolen i dag</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2010021600240' target='_'>Marthinsen, Edgar,Langtidsbrukere av sosialhjelp ved Byåsen sosialtjeneste i 1998,1999</a>\n",
       "                <td>Utsikter til</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>, trygd eller fortsatt sosialhjelp ?</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2010021600240' target='_'>Marthinsen, Edgar,Langtidsbrukere av sosialhjelp ved Byåsen sosialtjeneste i 1998,1999</a>\n",
       "                <td>Løsningsfokusert</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>47</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2010021600240' target='_'>Marthinsen, Edgar,Langtidsbrukere av sosialhjelp ved Byåsen sosialtjeneste i 1998,1999</a>\n",
       "                <td>hjelpe dem og hvordan framtidsutsiktene var med hensyn til det å fa</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>, bli trygdet eller om de fortsatt måtte basere seg på å</td>\n",
       "                </tr>\n",
       "<tr>\n",
       "            <td>\n",
       "                <a href='http://www.nb.no/items/URN:NBN:no-nb_digibok_2010021600240' target='_'>Marthinsen, Edgar,Langtidsbrukere av sosialhjelp ved Byåsen sosialtjeneste i 1998,1999</a>\n",
       "                <td>endringer som foregikk samtidig på kontoret , bl.a. innføringen av såkalt løsningsfokusert</td>\n",
       "                <td>arbeid</td>\n",
       "                <td style='text-align:left'>( LØFT ) . Deretter følger en omtale av resultatene fra medarbeidernes</td>\n",
       "                </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\n",
    "get_konk('arbeid',params={'corpus':'bok', 'title':'%','author': '%%', 'before':18,'after':18, 'size':2, 'offset':0})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trendplots\n",
    "\n",
    "Any word can be plotted and compared, the function *get_ngram* extracts total frequencies from texts. For a simpler interface, one may also go to the web service https://www.nb.no/sp_tjenester/beta/ngram_1/#ngram/query?terms=trend&lang=all&case_sens=0&freq=rel&corpus=bok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-33b419d46524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marbeid_ng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ngram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'onani'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'corpus'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'bok'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-f35494292953>\u001b[0m in \u001b[0;36mget_ngram\u001b[1;34m(word, params)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mpara\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://api.nb.no/ngram/ngram'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpara\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;31m#r.columns = [word]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m                 \u001b[1;31m# TODO speed up Series case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    975\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_from_nested_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "arbeid_ng = get_ngram('onani', {'corpus':'bok'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relativization \n",
    "\n",
    "In order to plot relative trends, one need to divide the total frequency with som other number that varies over year, like the frequency of all words. Here we use the relative frequency of one trend over another, and choose hi frequency words like coordination and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_ng = get_ngram('og',{'corpus':'bok'})\n",
    "punct_ng = get_ngram('.', {'corpus': 'bok'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotrelative(coord_ng,punct_ng)\n",
    "plt.savefig('turku.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative plot\n",
    "\n",
    "The first trend line can be relativized using *coord_ng* and *punct_ng*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotrelative(arbeid_ng, coord_ng + punct_ng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine identity\n",
    "\n",
    "Identity is modelled in terms of what expressed in letters going from immigrants. For this purpose we try out an approach where a particular selection of words, words that are believed to connect to identity dimensions like family, work, health among others, and are compared with other texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URNs for the texts\n",
    "\n",
    "In order to specify a particular corpus the function *get_urns* is used. It finds books based on title, author or year, and suggests a couple of reduced URN-identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The letters \n",
    "a_urns = get_urns({'title':'%amerika til%', 'year':1980})\n",
    "amerika_urns = [x[0] for x in a_urns]\n",
    "a_urns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The letters \n",
    "a_urns2 = get_urns({'title':'%amerika%','year':1950, 'next':50})\n",
    "amerika_urns2 = [x[0] for x in a_urns2]\n",
    "a_urns2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the set of URNs that are taken along are just the reduced ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_urns({'title':'%kaleval%'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URNs can be expected for frequency distribution\n",
    "\n",
    "The command is *get_urnfreq* which simply takes a reduced URN and returns the top N words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_urnfreq(2008090300033, top=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the result to a dataframe for further processing\n",
    "\n",
    "urnfreq = pd.DataFrame.from_dict(\n",
    "    dict(\n",
    "        get_urnfreq(2008090300033, top=1500)), \n",
    "                       orient='index').sort_values(by=0, ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot frequencies as barcharts\n",
    "\n",
    "Commands may look cryptic - they are here just to show that the visuals are produced by a single line. In practice a more user friendly interface is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urnfreq.iloc[:30].plot(kind='bar', figsize=(15,10), legend=False, fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urnfreq.iloc[300:350].sort_values(by=0).plot(kind='barh',figsize=(18,18), fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URN-sets for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_urn = get_urns({'author':'Hamsun%knut%', 'year':1955})\n",
    "u1980 = get_urns({'year':1980})\n",
    "u1920 = get_urns({'year':1920})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_urns = [x[0] for x in u1980[:60]]\n",
    "hamsun_urns = [x[0] for x in u1920[:5]]\n",
    "old_urns = [x[0] for x in u1920[2:38]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_urns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a collection of marker words\n",
    "\n",
    "These words may function as markers of identity, and serve as a comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_words = ['arbeid', \n",
    "               'arbeidet', 'arbeide',\n",
    "               'land','landet','hjem','hjemme','hjemlandet',\n",
    "               'rejse', 'reise','sjøen','hav','havet',\n",
    "               'jorda','åkeren', \n",
    "               'gårdbruker','Gaardbruger',\n",
    "               'slite', 'streve', \n",
    "               'familie','familien','kone','bror','broren','søster',\n",
    "               'venn', 'venner','kamerat','kameraten','venninne','venninnen',\n",
    "               'amerikanerne','amerikanere','landsmenn', 'landsmand','landsmann','engelsk', 'engelskmann',\n",
    "               'indianer','indianere',\n",
    "              'fattige','rike','fattigdom','rikdom','rigdom', 'Rige','rige','Fattige', 'Rigdom']\n",
    "hi_words = ['og','.','i',]\n",
    "words = embed_words + hi_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data for the words \n",
    "\n",
    "Each word is extracted from each urnset. The function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amerika_brev_urn = get_words_from_urnset(words, amerika_urns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amerika_urn2 = get_words_from_urnset(words, amerika_urns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsun_urn = get_words_from_urnset(words, hamsun_urns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_urn = get_words_from_urnset(words, rand_urns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_urn = get_words_from_urnset(words, old_urns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The letters\n",
    "\n",
    "Her we look at the data from letters using a heatmap. Each URN is represented in a column, and the individual words from the marker set is coloured according to its frequency within a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(\n",
    "pd.DataFrame(amerika_urn2).loc[embed_words]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data can be summarized over rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(pd.DataFrame(pd.DataFrame(amerika_urn2).loc[embed_words].sum(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the process for the other urn_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(\n",
    "pd.DataFrame(\n",
    "    hamsun_urn  # <=== fill in urnset here\n",
    ").loc[embed_words]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the URN-sets with each other\n",
    "\n",
    "In the comparison all the urnsets are aggregated to one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(\n",
    "    pd.concat([\n",
    "    pd.DataFrame(amerika_brev_urn).loc[embed_words].sum(axis = 1),\n",
    "    pd.DataFrame(amerika_urn2).loc[embed_words].sum(axis = 1),\n",
    "    pd.DataFrame(hamsun_urn).loc[embed_words].sum(axis = 1),\n",
    "    pd.DataFrame(rand_urn).loc[embed_words].sum(axis = 1),\n",
    "    pd.DataFrame(old_urn).loc[embed_words].sum(axis = 1)\n",
    "    ],\n",
    "    axis=1\n",
    "))\n",
    "\n",
    "# column names for easy interpretation\n",
    "\n",
    "result.columns = 'A-Brev Amerika Hamsun Rand Old'.split()\n",
    "heatmap(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing by way of division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "comparo = pd.DataFrame(\n",
    "    pd.DataFrame(\n",
    "        amerika_brev_urn).loc[embed_words].sum(axis=1)/pd.DataFrame(\n",
    "        hamsun_urn).loc[embed_words].sum(axis=1))\n",
    "comparo=comparo.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "comparo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
